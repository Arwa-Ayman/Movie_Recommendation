{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI3Gr0dstn-Q",
        "outputId": "01075a12-ee1f-414a-d707-b4dd994ed149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (2.0.2)\n",
            "Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvAhmjqivtHM",
        "outputId": "9d51d7fd-88d9-4f05-d113-cc6016d36b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.11/dist-packages (1.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import operator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from deap import base, creator, tools, gp\n",
        "from deap import algorithms\n",
        "from multiprocessing import Pool\n",
        "import logging\n",
        "import time\n",
        "\n",
        "# Setup logging to ensure output in Colab\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[logging.StreamHandler()])\n",
        "\n",
        "# Load MovieLens dataset\n",
        "def load_data(movies_path='movies.csv', ratings_path='ratings.csv'):\n",
        "    logging.info(\"Loading data...\")\n",
        "    try:\n",
        "        movies = pd.read_csv(movies_path)\n",
        "        ratings = pd.read_csv(ratings_path)\n",
        "        print(f\"Loaded {len(movies)} movies and {len(ratings)} ratings\")\n",
        "        return movies, ratings\n",
        "    except FileNotFoundError as e:\n",
        "        logging.error(f\"File not found: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading data: {e}\")\n",
        "        raise\n",
        "\n",
        "# Split data per user into train and test sets\n",
        "def user_train_test_split(ratings, test_size=0.2, cache_file='/content/train_test_split.pkl'):\n",
        "    if os.path.exists(cache_file):\n",
        "        logging.info(\"Loading train/test split from cache...\")\n",
        "        with open(cache_file, 'rb') as f:\n",
        "            train_df, test_df = pickle.load(f)\n",
        "        print(f\"Loaded cached train/test split: {len(train_df)} train, {len(test_df)} test\")\n",
        "        return train_df, test_df\n",
        "\n",
        "    logging.info(\"Splitting data...\")\n",
        "    train_data = []\n",
        "    test_data = []\n",
        "    for user, group in ratings.groupby('userId'):\n",
        "        if len(group) < 5:\n",
        "            train_data.extend(group.to_dict('records'))\n",
        "            continue\n",
        "        train, test = train_test_split(group, test_size=test_size, random_state=42)\n",
        "        train_data.extend(train.to_dict('records'))\n",
        "        test_data.extend(test.to_dict('records'))\n",
        "\n",
        "    train_df = pd.DataFrame(train_data)\n",
        "    test_df = pd.DataFrame(test_data)\n",
        "    print(f\"Split data: {len(train_df)} train, {len(test_df)} test\")\n",
        "\n",
        "    try:\n",
        "        with open(cache_file, 'wb') as f:\n",
        "            pickle.dump((train_df, test_df), f)\n",
        "        logging.info(\"Cached train/test split\")\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Failed to cache split: {e}\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Build feature maps including genre information\n",
        "def build_feature_maps(train_df, movies_df, cache_file='/content/feature_maps.pkl'):\n",
        "    if os.path.exists(cache_file):\n",
        "        logging.info(\"Loading feature maps from cache...\")\n",
        "        with open(cache_file, 'rb') as f:\n",
        "            feature_maps = pickle.load(f)\n",
        "        print(f\"Loaded cached feature maps\")\n",
        "        return feature_maps\n",
        "\n",
        "    logging.info(\"Building feature maps...\")\n",
        "    user_avg = train_df.groupby('userId')['rating'].mean().to_dict()\n",
        "    item_avg = train_df.groupby('movieId')['rating'].mean().to_dict()\n",
        "    item_count = train_df.groupby('movieId')['rating'].count().to_dict()\n",
        "\n",
        "    movies_df['genres'] = movies_df['genres'].fillna('Unknown').str.split('|')\n",
        "    item_genres = movies_df.set_index('movieId')['genres'].to_dict()\n",
        "\n",
        "    ratings_with_genres = train_df.merge(movies_df[['movieId', 'genres']], on='movieId', how='left')\n",
        "    ratings_with_genres['genres'] = ratings_with_genres['genres'].apply(lambda x: x if isinstance(x, list) else ['Unknown'])\n",
        "    user_genre_prefs = ratings_with_genres.explode('genres').groupby(['userId', 'genres'])['rating'].mean().unstack(fill_value=0)\n",
        "\n",
        "    user_item_genre_scores = {}\n",
        "    for user in train_df['userId'].unique():\n",
        "        user_item_genre_scores[user] = {}\n",
        "        for item in item_avg.keys():\n",
        "            genres = item_genres.get(item, ['Unknown'])\n",
        "            score = sum(user_genre_prefs.get(genre, {}).get(user, 0) for genre in genres) / (len(genres) if genres else 1)\n",
        "            user_item_genre_scores[user][item] = score\n",
        "\n",
        "    candidate_items_per_user = {}\n",
        "    all_items = set(item_avg.keys())\n",
        "    for user in train_df['userId'].unique():\n",
        "        seen = set(train_df[train_df['userId'] == user]['movieId'])\n",
        "        candidate_items_per_user[user] = list(all_items - seen)\n",
        "\n",
        "    feature_maps = (user_avg, item_avg, item_count, item_genres, user_item_genre_scores, candidate_items_per_user)\n",
        "    print(f\"Built feature maps: {len(user_avg)} users, {len(item_avg)} items\")\n",
        "\n",
        "    try:\n",
        "        with open(cache_file, 'wb') as f:\n",
        "            pickle.dump(feature_maps, f)\n",
        "        logging.info(\"Cached feature maps\")\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Failed to cache feature maps: {e}\")\n",
        "\n",
        "    return feature_maps\n",
        "\n",
        "# Recommend top-N items for a user using a GP individual (vectorized)\n",
        "def recommend(individual, user, candidate_items, user_avg, item_avg, item_count, user_item_genre_scores, N=10):\n",
        "    func = toolbox.compile(expr=individual)\n",
        "    u_avg = np.array([user_avg.get(user, 3)] * len(candidate_items))\n",
        "    i_avg = np.array([item_avg.get(item, 3) for item in candidate_items])\n",
        "    i_count = np.array([item_count.get(item, 1) for item in candidate_items])\n",
        "    g_score = np.array([user_item_genre_scores.get(user, {}).get(item, 0) for item in candidate_items])\n",
        "\n",
        "    try:\n",
        "        scores = func(u_avg, i_avg, i_count, g_score)\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Vectorized scoring failed: {e}, falling back to loop\")\n",
        "        scores = np.array([func(u_avg[i], i_avg[i], i_count[i], g_score[i]) for i in range(len(candidate_items))])\n",
        "\n",
        "    top_indices = np.argsort(scores)[::-1][:N]\n",
        "    return [candidate_items[i] for i in top_indices]\n",
        "\n",
        "# Fitness evaluation for a single individual, returning metrics\n",
        "def evaluate_individual(individual, test_users_subset, train_df, test_df, user_avg, item_avg, item_count, user_item_genre_scores, candidate_items_per_user):\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    user_metrics = {}\n",
        "\n",
        "    for user in test_users_subset:\n",
        "        test_items = set(test_df[test_df['userId'] == user]['movieId'])\n",
        "        candidate_items = candidate_items_per_user.get(user, [])\n",
        "        if not candidate_items or not test_items:\n",
        "            continue\n",
        "        recs = recommend(individual, user, candidate_items, user_avg, item_avg, item_count, user_item_genre_scores, N=10)\n",
        "        hits = len(set(recs) & test_items)\n",
        "        precision = hits / 10\n",
        "        recall = hits / len(test_items) if test_items else 0\n",
        "        f1 = (2 * precision * recall) / (precision + recall + 1e-8)\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "        user_metrics[user] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
        "\n",
        "    avg_prec = np.mean(precision_scores) if precision_scores else 0\n",
        "    avg_rec = np.mean(recall_scores) if recall_scores else 0\n",
        "    avg_f1 = np.mean(f1_scores) if f1_scores else 0\n",
        "    return avg_f1, user_metrics\n",
        "\n",
        "# Wrapper for parallel evaluation\n",
        "def evaluate(individual):\n",
        "    return evaluate_individual(\n",
        "        individual, test_users_subset, train_df, test_df,\n",
        "        user_avg, item_avg, item_count, user_item_genre_scores, candidate_items_per_user\n",
        "    )\n",
        "\n",
        "# Setup GP\n",
        "pset = gp.PrimitiveSet(\"MAIN\", 4)\n",
        "pset.renameArguments(ARG0='u_avg')\n",
        "pset.renameArguments(ARG1='i_avg')\n",
        "pset.renameArguments(ARG2='i_count')\n",
        "pset.renameArguments(ARG3='g_score')\n",
        "\n",
        "pset.addPrimitive(np.add, 2)\n",
        "pset.addPrimitive(np.subtract, 2)\n",
        "pset.addPrimitive(np.multiply, 2)\n",
        "pset.addPrimitive(lambda x, y: np.divide(x, y + 1e-5), 2, name=\"safe_div\")\n",
        "pset.addPrimitive(np.tanh, 1)\n",
        "pset.addPrimitive(np.abs, 1)\n",
        "\n",
        "if not hasattr(creator, 'FitnessMax'):\n",
        "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "if not hasattr(creator, 'Individual'):\n",
        "    creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=3)\n",
        "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"compile\", gp.compile, pset=pset)\n",
        "toolbox.register(\"evaluate\", evaluate)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"mate\", gp.cxOnePoint)\n",
        "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr, pset=pset)\n",
        "\n",
        "toolbox.decorate(\"mate\", gp.staticLimit(key=len, max_value=17))\n",
        "toolbox.decorate(\"mutate\", gp.staticLimit(key=len, max_value=17))\n",
        "\n",
        "# Early stopping callback\n",
        "print(\"Defining EarlyStopping class...\")\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience):  # Fixed method name\n",
        "        self.patience = patience\n",
        "        self.best_fitness = -np.inf\n",
        "        self.best_gen = 0\n",
        "        self.gen = 0\n",
        "        print(f\"EarlyStopping initialized with patience={self.patience}\")\n",
        "\n",
        "    def __call__(self, population, toolbox, halloffame):  # Fixed method name\n",
        "        self.gen += 1\n",
        "        current_best = halloffame[0].fitness.values[0]\n",
        "        if current_best > self.best_fitness:\n",
        "            self.best_fitness = current_best\n",
        "            self.best_gen = self.gen\n",
        "        if self.gen - self.best_gen >= self.patience:\n",
        "            logging.info(f\"Early stopping at generation {self.gen}: no improvement for {self.patience} generations\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "# Custom evolutionary algorithm with early stopping\n",
        "def custom_eaSimple(population, toolbox, cxpb, mutpb, ngen, stats=None, halloffame=None, verbose=False):\n",
        "    logbook = tools.Logbook()\n",
        "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
        "\n",
        "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
        "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "    for ind, fit in zip(invalid_ind, fitnesses):\n",
        "        ind.fitness.values = fit[0],\n",
        "        ind.user_metrics = fit[1]\n",
        "\n",
        "    if halloffame is not None:\n",
        "        halloffame.update(population)\n",
        "\n",
        "    early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "    for gen in range(ngen + 1):\n",
        "        offspring = toolbox.select(population, len(population))\n",
        "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
        "\n",
        "        nevals = 0\n",
        "        for i in range(1, len(offspring), 2):\n",
        "            if random.random() < cxpb:\n",
        "                offspring[i-1], offspring[i] = toolbox.mate(offspring[i-1], offspring[i])\n",
        "                del offspring[i-1].fitness.values, offspring[i].fitness.values\n",
        "                nevals += 2\n",
        "        for i in range(len(offspring)):\n",
        "            if random.random() < mutpb:\n",
        "                offspring[i], = toolbox.mutate(offspring[i])\n",
        "                del offspring[i].fitness.values\n",
        "                nevals += 1\n",
        "\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit[0],\n",
        "            ind.user_metrics = fit[1]\n",
        "\n",
        "        if halloffame is not None:\n",
        "            halloffame.update(offspring)\n",
        "\n",
        "        population[:] = offspring\n",
        "\n",
        "        record = stats.compile(population) if stats else {}\n",
        "        logbook.record(gen=gen, nevals=nevals, **record)\n",
        "        if verbose:\n",
        "            print(logbook.stream)\n",
        "\n",
        "        if early_stopping(population, toolbox, halloffame):\n",
        "            break\n",
        "\n",
        "    return population, logbook\n",
        "\n",
        "# Main execution\n",
        "print(\"Starting execution...\")\n",
        "start_time = time.time()\n",
        "logging.info(\"Loading data...\")\n",
        "movies_df, ratings_df = load_data()\n",
        "\n",
        "logging.info(\"Splitting data...\")\n",
        "train_df, test_df = user_train_test_split(ratings_df)\n",
        "\n",
        "logging.info(\"Building feature maps...\")\n",
        "user_avg, item_avg, item_count, item_genres, user_item_genre_scores, candidate_items_per_user = build_feature_maps(train_df, movies_df)\n",
        "\n",
        "logging.info(\"Preparing users...\")\n",
        "train_users = train_df['userId'].unique()\n",
        "test_users = test_df['userId'].unique()\n",
        "random.seed(42)\n",
        "test_users_subset = list(test_users)\n",
        "logging.info(f\"Using {len(test_users_subset)} test users for evaluation\")\n",
        "print(f\"Using {len(test_users_subset)} test users for evaluation\")\n",
        "print(f\"Test user IDs: {sorted(test_users_subset)}\")\n",
        "\n",
        "# Setup parallel evaluation\n",
        "logging.info(\"Setting up parallel evaluation...\")\n",
        "pool = Pool()\n",
        "toolbox.register(\"map\", pool.map)\n",
        "\n",
        "pop = toolbox.population(n=25)\n",
        "hof = tools.HallOfFame(1)\n",
        "\n",
        "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "stats.register(\"avg\", np.mean)\n",
        "stats.register(\"max\", np.max)\n",
        "\n",
        "logging.info(\"Starting GP evolution...\")\n",
        "print(\"Starting GP evolution...\")\n",
        "pop, log = custom_eaSimple(\n",
        "    pop, toolbox, cxpb=0.5, mutpb=0.3, ngen=8,\n",
        "    stats=stats, halloffame=hof, verbose=True\n",
        ")\n",
        "\n",
        "# Cleanup\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "# Output results\n",
        "logging.info(f\"Best GP Individual: {hof[0]}\")\n",
        "logging.info(f\"Best F1 Score: {hof[0].fitness.values[0]:.4f}\")\n",
        "logging.info(f\"Total runtime: {time.time() - start_time:.2f} seconds\")\n",
        "print(f\"Best GP Individual: {hof[0]}\")\n",
        "print(f\"Best F1 Score: {hof[0].fitness.values[0]:.4f}\")\n",
        "print(f\"Total runtime: {time.time() - start_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B4UCFV7teSt",
        "outputId": "1beab0ac-d5c6-4928-c841-8ad91f327943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defining EarlyStopping class...\n",
            "Starting execution...\n",
            "Loaded 9742 movies and 100836 ratings\n",
            "Loaded cached train/test split: 80419 train, 20417 test\n",
            "Loaded cached feature maps\n",
            "Using 610 test users for evaluation\n",
            "Test user IDs: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(39), np.int64(40), np.int64(41), np.int64(42), np.int64(43), np.int64(44), np.int64(45), np.int64(46), np.int64(47), np.int64(48), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(53), np.int64(54), np.int64(55), np.int64(56), np.int64(57), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(63), np.int64(64), np.int64(65), np.int64(66), np.int64(67), np.int64(68), np.int64(69), np.int64(70), np.int64(71), np.int64(72), np.int64(73), np.int64(74), np.int64(75), np.int64(76), np.int64(77), np.int64(78), np.int64(79), np.int64(80), np.int64(81), np.int64(82), np.int64(83), np.int64(84), np.int64(85), np.int64(86), np.int64(87), np.int64(88), np.int64(89), np.int64(90), np.int64(91), np.int64(92), np.int64(93), np.int64(94), np.int64(95), np.int64(96), np.int64(97), np.int64(98), np.int64(99), np.int64(100), np.int64(101), np.int64(102), np.int64(103), np.int64(104), np.int64(105), np.int64(106), np.int64(107), np.int64(108), np.int64(109), np.int64(110), np.int64(111), np.int64(112), np.int64(113), np.int64(114), np.int64(115), np.int64(116), np.int64(117), np.int64(118), np.int64(119), np.int64(120), np.int64(121), np.int64(122), np.int64(123), np.int64(124), np.int64(125), np.int64(126), np.int64(127), np.int64(128), np.int64(129), np.int64(130), np.int64(131), np.int64(132), np.int64(133), np.int64(134), np.int64(135), np.int64(136), np.int64(137), np.int64(138), np.int64(139), np.int64(140), np.int64(141), np.int64(142), np.int64(143), np.int64(144), np.int64(145), np.int64(146), np.int64(147), np.int64(148), np.int64(149), np.int64(150), np.int64(151), np.int64(152), np.int64(153), np.int64(154), np.int64(155), np.int64(156), np.int64(157), np.int64(158), np.int64(159), np.int64(160), np.int64(161), np.int64(162), np.int64(163), np.int64(164), np.int64(165), np.int64(166), np.int64(167), np.int64(168), np.int64(169), np.int64(170), np.int64(171), np.int64(172), np.int64(173), np.int64(174), np.int64(175), np.int64(176), np.int64(177), np.int64(178), np.int64(179), np.int64(180), np.int64(181), np.int64(182), np.int64(183), np.int64(184), np.int64(185), np.int64(186), np.int64(187), np.int64(188), np.int64(189), np.int64(190), np.int64(191), np.int64(192), np.int64(193), np.int64(194), np.int64(195), np.int64(196), np.int64(197), np.int64(198), np.int64(199), np.int64(200), np.int64(201), np.int64(202), np.int64(203), np.int64(204), np.int64(205), np.int64(206), np.int64(207), np.int64(208), np.int64(209), np.int64(210), np.int64(211), np.int64(212), np.int64(213), np.int64(214), np.int64(215), np.int64(216), np.int64(217), np.int64(218), np.int64(219), np.int64(220), np.int64(221), np.int64(222), np.int64(223), np.int64(224), np.int64(225), np.int64(226), np.int64(227), np.int64(228), np.int64(229), np.int64(230), np.int64(231), np.int64(232), np.int64(233), np.int64(234), np.int64(235), np.int64(236), np.int64(237), np.int64(238), np.int64(239), np.int64(240), np.int64(241), np.int64(242), np.int64(243), np.int64(244), np.int64(245), np.int64(246), np.int64(247), np.int64(248), np.int64(249), np.int64(250), np.int64(251), np.int64(252), np.int64(253), np.int64(254), np.int64(255), np.int64(256), np.int64(257), np.int64(258), np.int64(259), np.int64(260), np.int64(261), np.int64(262), np.int64(263), np.int64(264), np.int64(265), np.int64(266), np.int64(267), np.int64(268), np.int64(269), np.int64(270), np.int64(271), np.int64(272), np.int64(273), np.int64(274), np.int64(275), np.int64(276), np.int64(277), np.int64(278), np.int64(279), np.int64(280), np.int64(281), np.int64(282), np.int64(283), np.int64(284), np.int64(285), np.int64(286), np.int64(287), np.int64(288), np.int64(289), np.int64(290), np.int64(291), np.int64(292), np.int64(293), np.int64(294), np.int64(295), np.int64(296), np.int64(297), np.int64(298), np.int64(299), np.int64(300), np.int64(301), np.int64(302), np.int64(303), np.int64(304), np.int64(305), np.int64(306), np.int64(307), np.int64(308), np.int64(309), np.int64(310), np.int64(311), np.int64(312), np.int64(313), np.int64(314), np.int64(315), np.int64(316), np.int64(317), np.int64(318), np.int64(319), np.int64(320), np.int64(321), np.int64(322), np.int64(323), np.int64(324), np.int64(325), np.int64(326), np.int64(327), np.int64(328), np.int64(329), np.int64(330), np.int64(331), np.int64(332), np.int64(333), np.int64(334), np.int64(335), np.int64(336), np.int64(337), np.int64(338), np.int64(339), np.int64(340), np.int64(341), np.int64(342), np.int64(343), np.int64(344), np.int64(345), np.int64(346), np.int64(347), np.int64(348), np.int64(349), np.int64(350), np.int64(351), np.int64(352), np.int64(353), np.int64(354), np.int64(355), np.int64(356), np.int64(357), np.int64(358), np.int64(359), np.int64(360), np.int64(361), np.int64(362), np.int64(363), np.int64(364), np.int64(365), np.int64(366), np.int64(367), np.int64(368), np.int64(369), np.int64(370), np.int64(371), np.int64(372), np.int64(373), np.int64(374), np.int64(375), np.int64(376), np.int64(377), np.int64(378), np.int64(379), np.int64(380), np.int64(381), np.int64(382), np.int64(383), np.int64(384), np.int64(385), np.int64(386), np.int64(387), np.int64(388), np.int64(389), np.int64(390), np.int64(391), np.int64(392), np.int64(393), np.int64(394), np.int64(395), np.int64(396), np.int64(397), np.int64(398), np.int64(399), np.int64(400), np.int64(401), np.int64(402), np.int64(403), np.int64(404), np.int64(405), np.int64(406), np.int64(407), np.int64(408), np.int64(409), np.int64(410), np.int64(411), np.int64(412), np.int64(413), np.int64(414), np.int64(415), np.int64(416), np.int64(417), np.int64(418), np.int64(419), np.int64(420), np.int64(421), np.int64(422), np.int64(423), np.int64(424), np.int64(425), np.int64(426), np.int64(427), np.int64(428), np.int64(429), np.int64(430), np.int64(431), np.int64(432), np.int64(433), np.int64(434), np.int64(435), np.int64(436), np.int64(437), np.int64(438), np.int64(439), np.int64(440), np.int64(441), np.int64(442), np.int64(443), np.int64(444), np.int64(445), np.int64(446), np.int64(447), np.int64(448), np.int64(449), np.int64(450), np.int64(451), np.int64(452), np.int64(453), np.int64(454), np.int64(455), np.int64(456), np.int64(457), np.int64(458), np.int64(459), np.int64(460), np.int64(461), np.int64(462), np.int64(463), np.int64(464), np.int64(465), np.int64(466), np.int64(467), np.int64(468), np.int64(469), np.int64(470), np.int64(471), np.int64(472), np.int64(473), np.int64(474), np.int64(475), np.int64(476), np.int64(477), np.int64(478), np.int64(479), np.int64(480), np.int64(481), np.int64(482), np.int64(483), np.int64(484), np.int64(485), np.int64(486), np.int64(487), np.int64(488), np.int64(489), np.int64(490), np.int64(491), np.int64(492), np.int64(493), np.int64(494), np.int64(495), np.int64(496), np.int64(497), np.int64(498), np.int64(499), np.int64(500), np.int64(501), np.int64(502), np.int64(503), np.int64(504), np.int64(505), np.int64(506), np.int64(507), np.int64(508), np.int64(509), np.int64(510), np.int64(511), np.int64(512), np.int64(513), np.int64(514), np.int64(515), np.int64(516), np.int64(517), np.int64(518), np.int64(519), np.int64(520), np.int64(521), np.int64(522), np.int64(523), np.int64(524), np.int64(525), np.int64(526), np.int64(527), np.int64(528), np.int64(529), np.int64(530), np.int64(531), np.int64(532), np.int64(533), np.int64(534), np.int64(535), np.int64(536), np.int64(537), np.int64(538), np.int64(539), np.int64(540), np.int64(541), np.int64(542), np.int64(543), np.int64(544), np.int64(545), np.int64(546), np.int64(547), np.int64(548), np.int64(549), np.int64(550), np.int64(551), np.int64(552), np.int64(553), np.int64(554), np.int64(555), np.int64(556), np.int64(557), np.int64(558), np.int64(559), np.int64(560), np.int64(561), np.int64(562), np.int64(563), np.int64(564), np.int64(565), np.int64(566), np.int64(567), np.int64(568), np.int64(569), np.int64(570), np.int64(571), np.int64(572), np.int64(573), np.int64(574), np.int64(575), np.int64(576), np.int64(577), np.int64(578), np.int64(579), np.int64(580), np.int64(581), np.int64(582), np.int64(583), np.int64(584), np.int64(585), np.int64(586), np.int64(587), np.int64(588), np.int64(589), np.int64(590), np.int64(591), np.int64(592), np.int64(593), np.int64(594), np.int64(595), np.int64(596), np.int64(597), np.int64(598), np.int64(599), np.int64(600), np.int64(601), np.int64(602), np.int64(603), np.int64(604), np.int64(605), np.int64(606), np.int64(607), np.int64(608), np.int64(609), np.int64(610)]\n",
            "Starting GP evolution...\n",
            "EarlyStopping initialized with patience=3\n",
            "gen\tnevals\tavg      \tmax    \n",
            "0  \t16    \t0.0471399\t0.08178\n",
            "1  \t24    \t0.0621861\t0.0817638\n",
            "2  \t19    \t0.0716985\t0.0817638\n",
            "3  \t26    \t0.0717771\t0.0821986\n",
            "4  \t25    \t0.0720197\t0.0826992\n",
            "5  \t21    \t0.0784885\t0.0826992\n",
            "6  \t18    \t0.0720419\t0.0825754\n",
            "7  \t23    \t0.0688982\t0.0826992\n",
            "Best GP Individual: multiply(add(i_avg, i_avg), multiply(absolute(i_count), absolute(i_count)))\n",
            "Best F1 Score: 0.0827\n",
            "Total runtime: 883.72 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and display recommended movies for a fixed user\n",
        "fixed_user_id = 1  # Change to 2 or another ID if desired\n",
        "print(f\"\\nRecommended Movies for User {fixed_user_id}:\")\n",
        "if fixed_user_id not in test_users_subset:\n",
        "    print(f\"Error: User {fixed_user_id} is not in test_users_subset. Choose from: {sorted(test_users_subset)}\")\n",
        "else:\n",
        "    candidate_items = candidate_items_per_user.get(fixed_user_id, [])\n",
        "    if not candidate_items:\n",
        "        print(f\"User {fixed_user_id}: No candidate items available\")\n",
        "    else:\n",
        "        recs = recommend(hof[0], fixed_user_id, candidate_items, user_avg, item_avg, item_count, user_item_genre_scores, N=10)\n",
        "        for i, movie_id in enumerate(recs, 1):\n",
        "            movie_info = movies_df[movies_df['movieId'] == movie_id]\n",
        "            if not movie_info.empty:\n",
        "                title = movie_info['title'].iloc[0]\n",
        "                genres = movie_info['genres'].iloc[0]\n",
        "                print(f\"{i}. {title} [{genres}]\")\n",
        "            else:\n",
        "                print(f\"{i}. Movie ID {movie_id} [Unknown]\")\n",
        "print()\n",
        "\n",
        "# Display evaluation metrics\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "avg_f1, user_metrics = evaluate(hof[0])  # Re-evaluate best individual\n",
        "avg_precision = np.mean([m['precision'] for m in user_metrics.values()])\n",
        "avg_recall = np.mean([m['recall'] for m in user_metrics.values()])\n",
        "print(f\"Average Precision (All Test Users): {avg_precision:.4f}\")\n",
        "print(f\"Average Recall (All Test Users): {avg_recall:.4f}\")\n",
        "print(f\"Average F1 Score (All Test Users): {avg_f1:.4f}\")\n",
        "print(f\"Metrics for User {fixed_user_id}:\")\n",
        "if fixed_user_id in user_metrics:\n",
        "    metrics = user_metrics[fixed_user_id]\n",
        "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
        "else:\n",
        "    print(f\"No metrics available for User {fixed_user_id}. Ensure user is in test set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG7Y5K4jt2CO",
        "outputId": "a34f3691-05c5-4da6-c3b3-fef772889bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommended Movies for User 1:\n",
            "1. Shawshank Redemption, The (1994) [Crime|Drama]\n",
            "2. Pulp Fiction (1994) [Comedy|Crime|Drama|Thriller]\n",
            "3. Star Wars: Episode IV - A New Hope (1977) [Action|Adventure|Sci-Fi]\n",
            "4. Terminator 2: Judgment Day (1991) [Action|Sci-Fi]\n",
            "5. Lord of the Rings: The Fellowship of the Ring, The (2001) [Adventure|Fantasy]\n",
            "6. Apollo 13 (1995) [Adventure|Drama|IMAX]\n",
            "7. Godfather, The (1972) [Crime|Drama]\n",
            "8. Lord of the Rings: The Return of the King, The (2003) [Action|Adventure|Drama|Fantasy]\n",
            "9. Lord of the Rings: The Two Towers, The (2002) [Adventure|Fantasy]\n",
            "10. Twelve Monkeys (a.k.a. 12 Monkeys) (1995) [Mystery|Sci-Fi|Thriller]\n",
            "\n",
            "\n",
            "Evaluation Metrics:\n",
            "Average Precision (All Test Users): 0.1656\n",
            "Average Recall (All Test Users): 0.0730\n",
            "Average F1 Score (All Test Users): 0.0827\n",
            "Metrics for User 1:\n",
            "Precision: 0.2000\n",
            "Recall: 0.0426\n",
            "F1 Score: 0.0702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQHmarqk2JkB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}